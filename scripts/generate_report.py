#!/usr/bin/env python3
"""
Museè„³æ³¢ãƒ‡ãƒ¼ã‚¿åŸºæœ¬åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

lib/eeg.py ã®é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚

Usage:
    python generate_report.py --data <CSV_PATH> [--output <REPORT_PATH>]
"""

import os
import sys
from pathlib import Path
import argparse
from datetime import datetime

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use("Agg")
import matplotlib.pyplot as plt

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(project_root))

# lib ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from lib import (
    load_mind_monitor_csv,
    calculate_band_statistics,
    calculate_hsi_statistics,
    prepare_mne_raw,
    filter_eeg_quality,
    calculate_psd,
    calculate_spectrogram,
    calculate_spectrogram_all_channels,
    calculate_paf,
    get_psd_peak_frequencies,
    calculate_frontal_theta,
    calculate_frontal_asymmetry,
    calculate_alpha_power,
    calculate_alpha_power_from_raw,
    calculate_spectral_entropy,
    calculate_spectral_entropy_time_series,
    calculate_segment_analysis,
    calculate_meditation_score,
    calculate_best_metrics,
    get_optics_data,
    analyze_fnirs,
    generate_session_summary,
    get_heart_rate_data,
    analyze_motion,
)
from lib.session_log import write_to_csv, write_to_google_sheets

# å¯è¦–åŒ–é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from lib.sensors.eeg.visualization import (
    plot_band_power_time_series,
    plot_psd,
    plot_spectrogram,
    plot_spectrogram_grid,
    plot_band_ratios,
    plot_paf,
    plot_raw_preview,
    plot_frontal_theta,
    plot_frontal_asymmetry,
)

from lib.visualization import (
    plot_segment_comparison,
    plot_fnirs_muse_style,
    plot_motion_heart_rate,
    create_motion_stats_table,
)
from lib.statistical_dataframe import create_statistical_dataframe


def format_timestamp_for_report(value):
    """Datetimeè¡¨ç¤ºã‚’ç§’ç²¾åº¦ã«æ•´å½¢"""
    if value is None:
        return 'N/A'
    if isinstance(value, (pd.Timestamp, datetime)):
        return value.strftime('%Y-%m-%d %H:%M:%S')
    if hasattr(value, 'strftime'):
        return value.strftime('%Y-%m-%d %H:%M:%S')
    return str(value)


def seconds_to_minutes(value):
    """ç§’ã‚’åˆ†è¡¨ç¤ºç”¨ã«å¤‰æ›"""
    try:
        return float(value) / 60.0
    except (TypeError, ValueError):
        return None


def generate_fnirs_stats_table(fnirs_stats: dict) -> pd.DataFrame:
    """fNIRSçµ±è¨ˆæƒ…å ±ã‚’DataFrameåŒ–ã—ã¦æ•´å½¢"""
    df_stats = pd.DataFrame(fnirs_stats).T
    df_stats = df_stats.rename(
        index={"left": "å·¦åŠçƒ", "right": "å³åŠçƒ"},
        columns={
            "hbo_mean": "HbOå¹³å‡",
            "hbo_std": "HbOæ¨™æº–åå·®",
            "hbo_min": "HbOæœ€å°",
            "hbo_max": "HbOæœ€å¤§",
            "hbr_mean": "HbRå¹³å‡",
            "hbr_std": "HbRæ¨™æº–åå·®",
            "hbr_min": "HbRæœ€å°",
            "hbr_max": "HbRæœ€å¤§",
        },
    )
    return df_stats[
        [
            "HbOå¹³å‡",
            "HbOæ¨™æº–åå·®",
            "HbOæœ€å°",
            "HbOæœ€å¤§",
            "HbRå¹³å‡",
            "HbRæ¨™æº–åå·®",
            "HbRæœ€å°",
            "HbRæœ€å¤§",
        ]
    ]


def generate_markdown_report(data_path, output_dir, results):
    """
    ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ

    Parameters
    ----------
    data_path : Path
        å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    output_dir : Path
        å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    results : dict
        åˆ†æçµæœã‚’æ ¼ç´ã—ãŸè¾æ›¸
    """
    report_path = output_dir / 'REPORT.md'

    print(f'ç”Ÿæˆä¸­: ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ¬ãƒãƒ¼ãƒˆ -> {report_path}')

    info = results.get('data_info', {})

    start_time = format_timestamp_for_report(info.get('start_time'))
    end_time = format_timestamp_for_report(info.get('end_time'))
    duration_min = seconds_to_minutes(info.get('duration_sec'))
    duration_str = f"{duration_min:.1f} åˆ†" if duration_min is not None else "N/A"

    report = f"""# Museè„³æ³¢ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆ

- **ç”Ÿæˆæ—¥æ™‚**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«**: `{data_path.name}`
- **è¨˜éŒ²æ™‚é–“**: {start_time} ~ {end_time}
- **è¨ˆæ¸¬æ™‚é–“**: {duration_str}

---

"""

    # ========================================
    # æ¥ç¶šå“è³ªï¼ˆHSIï¼‰
    # ========================================
    if 'hsi_stats' in results:
        hsi_data = results['hsi_stats']
        overall_quality = hsi_data.get('overall_quality')
        good_ratio = hsi_data.get('good_ratio', 0.0) * 100

        report += "## ğŸ“¡ æ¥ç¶šå“è³ª\n\n"

        # å…¨ä½“è©•ä¾¡
        if overall_quality is not None:
            report += f"- **ç·åˆå“è³ªã‚¹ã‚³ã‚¢**: {overall_quality:.2f}\n"
            report += f"- **Goodå“è³ªç‡**: {good_ratio:.1f}%\n\n"

        # ãƒãƒ£ãƒãƒ«åˆ¥è©³ç´°
        if not hsi_data['statistics'].empty:
            report += "### ãƒãƒ£ãƒãƒ«åˆ¥è©³ç´°\n\n"
            report += hsi_data['statistics'].to_markdown(index=False, floatfmt='.2f')
            report += "\n\n"
            report += "> **æ³¨**: 1.0=Good, 2.0=Medium, 4.0=Bad\n\n"

    # ========================================
    # ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    # ========================================
    if 'raw_preview_img' in results:
        report += "## ğŸ§¾ ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼\n\n"
        report += f"![ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒƒãƒˆ](img/{results['raw_preview_img']})\n\n"
        report += "> **æ³¨**: ãƒ•ã‚£ãƒ«ã‚¿é©ç”¨å¾ŒEEGã®åˆæœŸæ•°åˆ†ï¼ˆÎ¼Vè¡¨ç¤ºï¼‰ã€‚ç•°å¸¸æ³¢å½¢ã®æ—©æœŸãƒã‚§ãƒƒã‚¯ç”¨ã€‚\n\n"

    # ========================================
    # åˆ†æã‚µãƒãƒªãƒ¼
    # ========================================
    report += "## ğŸ“Š åˆ†æã‚µãƒãƒªãƒ¼\n\n"

    # ç·åˆã‚¹ã‚³ã‚¢
    if 'session_score' in results:
        report += "### ç·åˆè©•ä¾¡\n\n"
        report += f"- **ç·åˆã‚¹ã‚³ã‚¢**: {results['session_score']:.1f}/100\n"

        # ã‚¹ã‚³ã‚¢å†…è¨³
        if 'session_score_breakdown' in results:
            report += "\n**ã‚¹ã‚³ã‚¢å†…è¨³**\n\n"
            breakdown = results['session_score_breakdown']
            score_labels = {
                'fmtheta': 'ç‘æƒ³æ·±åº¦ (FmÎ¸)',
                'spectral_entropy': 'é›†ä¸­åº¦ (SE)',
                'theta_alpha_ratio': 'ç‘æƒ³æ·±åº¦ (Î¸/Î±)',
                'beta_alpha_ratio': 'è¦šé†’åº¦ (Î²/Î±)',
                'iaf_stability': 'å‘¨æ³¢æ•°å®‰å®šæ€§ (IAF)',
            }
            for key, label in score_labels.items():
                if key in breakdown:
                    score_100 = breakdown[key] * 100
                    report += f"- {label}: {score_100:.1f}/100\n"
        report += "\n"

    # ä¸»è¦æŒ‡æ¨™ã‚µãƒãƒªãƒ¼ï¼ˆMean / Best ãƒ†ãƒ¼ãƒ–ãƒ«ï¼‰
    if 'mean_metrics' in results and 'best_metrics' in results:
        report += "### ä¸»è¦æŒ‡æ¨™ã‚µãƒãƒªãƒ¼\n\n"

        mean_m = results['mean_metrics']
        best_m = results['best_metrics']

        # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼
        report += "| æŒ‡æ¨™ | Mean | Best | å˜ä½ |\n"
        report += "|:-----|-----:|-----:|:-----|\n"

        # å„æŒ‡æ¨™ã®è¡Œã‚’è¿½åŠ 
        metrics_config = [
            ('FmÎ¸', 'fm_theta_mean', 'fm_theta_best', 'dB'),
            ('IAF', 'iaf_mean', 'iaf_best', 'Hz'),
            ('Alpha', 'alpha_mean', 'alpha_best', 'dB'),
            ('Beta', 'beta_mean', 'beta_best', 'dB'),
            ('Î¸/Î±', 'theta_alpha_mean', 'theta_alpha_best', 'ratio'),
        ]

        for label, mean_key, best_key, unit in metrics_config:
            mean_val = mean_m.get(mean_key)
            best_val = best_m.get(best_key)

            mean_str = f"{mean_val:.3f}" if mean_val is not None and not np.isnan(mean_val) else "N/A"
            best_str = f"{best_val:.3f}" if best_val is not None and not np.isnan(best_val) else "N/A"

            report += f"| {label} | {mean_str} | {best_str} | {unit} |\n"

        report += "\n"

    # ãƒ”ãƒ¼ã‚¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŒºé–“
    segment_keys = {'segment_table', 'segment_plot', 'segment_peak_range'}
    if any(key in results for key in segment_keys):
        peak_range = results.get('segment_peak_range')
        peak_score = results.get('segment_peak_score')
        if peak_range:
            report += "### ãƒ”ãƒ¼ã‚¯ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹\n\n"
            if peak_score is not None:
                report += f"- **æœ€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŒºé–“**: {peak_range}\n"
                report += f"- **ã‚¹ã‚³ã‚¢**: {peak_score:.1f}/100\n\n"
            else:
                report += f"- **æœ€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŒºé–“**: {peak_range}\n\n"

    # ========================================
    # å‘¨æ³¢æ•°å¸¯åŸŸåˆ†æ
    # ========================================
    band_power_keys = {
        'band_power_img',
        'psd_img',
        'spectrogram_img'
    }
    if any(key in results for key in band_power_keys):
        report += "## ğŸ§  å‘¨æ³¢æ•°å¸¯åŸŸåˆ†æ\n\n"

        if 'band_power_img' in results:
            report += "### ãƒãƒ³ãƒ‰ãƒ‘ãƒ¯ãƒ¼æ™‚ç³»åˆ—\n\n"
            report += f"![ãƒãƒ³ãƒ‰ãƒ‘ãƒ¯ãƒ¼æ™‚ç³»åˆ—](img/{results['band_power_img']})\n\n"

        if 'psd_img' in results:
            report += "### ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«å¯†åº¦ï¼ˆPSDï¼‰\n\n"
            report += f"![PSD](img/{results['psd_img']})\n\n"

        if 'spectrogram_img' in results:
            report += "### ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ \n\n"
            report += f"![ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ](img/{results['spectrogram_img']})\n\n"

    # ========================================
    # ç‰¹å¾´çš„æŒ‡æ¨™åˆ†æ
    # ========================================
    fmtheta_keys = {'frontal_theta_img', 'frontal_theta_stats', 'frontal_theta_increase'}
    paf_keys = {'paf_img', 'paf_summary', 'iaf'}
    faa_keys = {'faa_img', 'faa_stats'}
    band_ratio_keys = {'band_ratios_img', 'band_ratios_stats'}

    if any(key in results for key in (fmtheta_keys | paf_keys | faa_keys | band_ratio_keys)):
        report += "## ğŸ¯ ç‰¹å¾´çš„æŒ‡æ¨™åˆ†æ\n\n"

        # Frontal Midline Theta
        if any(key in results for key in fmtheta_keys):
            report += "### Frontal Midline Theta (FmÎ¸)\n\n"

            if 'frontal_theta_img' in results:
                report += f"![Frontal Midline Theta](img/{results['frontal_theta_img']})\n\n"

            if 'frontal_theta_stats' in results:
                stats_df = results['frontal_theta_stats']
                if 'Unit' in stats_df.columns:
                    stats_df = stats_df.drop(columns=['Unit'])
                report += stats_df.to_markdown(index=False, floatfmt='.3f')
                report += "\n\n"
                report += "> å˜ä½: dB (10Ã—logâ‚â‚€(Î¼VÂ²))\n\n"

            if 'frontal_theta_increase' in results:
                inc = results['frontal_theta_increase']
                if pd.notna(inc):
                    report += f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾ŒåŠã®å¹³å‡FmÎ¸ã¯å‰åŠæ¯”ã§ **{inc:+.1f}%** å¤‰åŒ–ã—ã¾ã—ãŸã€‚\n\n"

        # Individual Alpha Frequency
        if any(key in results for key in paf_keys):
            report += "### Individual Alpha Frequency (IAF)\n\n"

            if 'paf_img' in results:
                report += f"![PAF](img/{results['paf_img']})\n\n"

            if 'iaf' in results:
                iaf_data = results['iaf']
                report += f"**IAF (Peak)**: {iaf_data['peak']:.2f} Hz / **IAF (CoG)**: {iaf_data['cog']:.2f} Hz\n\n"

            if 'paf_summary' in results:
                report += "**ãƒãƒ£ãƒãƒ«åˆ¥è©³ç´°**\n\n"
                report += results['paf_summary'].to_markdown(index=False, floatfmt='.2f')
                report += "\n\n"

        # Alpha Power (Brain Recharge Score)
        if 'alpha_power_score' in results:
            report += "### Alpha Power (Brain Recharge Score)\n\n"
            score = results['alpha_power_score']
            alpha_db = results['alpha_power_db']
            report += f"**Brain Recharge Score**: {score:.1f} dBx\n\n"
            report += f"**Alpha Power**: {alpha_db:.2f} dB\n\n"

            if 'alpha_power_stats' in results:
                stats_df = results['alpha_power_stats']
                if 'Unit' in stats_df.columns:
                    stats_df = stats_df.drop(columns=['Unit'])
                report += stats_df.to_markdown(index=False, floatfmt='.2f')
                report += "\n\n"

            report += "> **è§£é‡ˆ**: Brain Recharge Scoreã¯Alphaæ³¢ãƒ‘ãƒ¯ãƒ¼ã«åŸºã¥ãç²¾ç¥çš„å›å¾©åº¦ã®æŒ‡æ¨™ã§ã™ã€‚é«˜ã„å€¤ã¯ãƒªãƒ©ãƒƒã‚¯ã‚¹ãƒ»å›å¾©çŠ¶æ…‹ã‚’ç¤ºå”†ã—ã¾ã™ã€‚\n"
            report += "> å˜ä½: Score=dBx, Alpha Power=dB\n\n"

        # Frontal Alpha Asymmetry
        if any(key in results for key in faa_keys):
            report += "### Frontal Alpha Asymmetry (FAA)\n\n"

            if 'faa_img' in results:
                report += f"![Frontal Alpha Asymmetry](img/{results['faa_img']})\n\n"

            if 'faa_stats' in results:
                report += results['faa_stats'].to_markdown(index=False, floatfmt='.3f')
                report += "\n\n"
                report += "> **è§£é‡ˆ**: FAA = ln(å³) - ln(å·¦)ã€‚æ­£å€¤ã¯å·¦åŠçƒå„ªä½ï¼ˆæ¥è¿‘å‹•æ©Ÿãƒ»ãƒã‚¸ãƒ†ã‚£ãƒ–æ„Ÿæƒ…ï¼‰ã€è² å€¤ã¯å³åŠçƒå„ªä½ï¼ˆå›é¿å‹•æ©Ÿãƒ»ãƒã‚¬ãƒ†ã‚£ãƒ–æ„Ÿæƒ…ï¼‰ã‚’ç¤ºå”†ã—ã¾ã™ã€‚\n\n"

        # Spectral Entropy
        if 'spectral_entropy_stats' in results:
            report += "### Spectral Entropy (SE)\n\n"
            report += results['spectral_entropy_stats'].to_markdown(index=False, floatfmt='.3f')
            report += "\n\n"

            if 'spectral_entropy_change' in results:
                change = results['spectral_entropy_change']
                if pd.notna(change):
                    interpretation = "ä½ä¸‹ï¼ˆæ³¨æ„é›†ä¸­ï¼‰" if change < 0 else "ä¸Šæ˜‡ï¼ˆæ³¨æ„æ•£æ¼«ï¼‰"
                    report += f"ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾ŒåŠã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¯å‰åŠæ¯”ã§ **{change:+.1f}%** å¤‰åŒ–ã—ã¾ã—ãŸã€‚\n"
                    report += f"**è§£é‡ˆ**: {interpretation}\n\n"

            report += "> **è§£é‡ˆ**: Spectral Entropyã¯å‘¨æ³¢æ•°æˆåˆ†ã®å¤šæ§˜æ€§ã‚’ç¤ºã—ã¾ã™ã€‚ä½ã„å€¤ã¯ç‰¹å®šã®å‘¨æ³¢æ•°å¸¯ã«é›†ä¸­ï¼ˆé›†ä¸­çŠ¶æ…‹ï¼‰ã€é«˜ã„å€¤ã¯åºƒå¸¯åŸŸã«åˆ†æ•£ï¼ˆæ•£æ¼«çŠ¶æ…‹ï¼‰ã‚’ç¤ºå”†ã—ã¾ã™ã€‚\n\n"

        # ãƒãƒ³ãƒ‰æ¯”ç‡
        if any(key in results for key in band_ratio_keys):
            report += "### ãƒãƒ³ãƒ‰æ¯”ç‡æŒ‡æ¨™\n\n"

            if 'band_ratios_img' in results:
                report += f"![ãƒãƒ³ãƒ‰æ¯”ç‡](img/{results['band_ratios_img']})\n\n"

            report += """> **æŒ‡æ¨™ã®è§£é‡ˆ**:
> - **Î¸/Î± (Theta/Alpha)**: ç‘æƒ³æ·±åº¦ã€‚å€¤ãŒé«˜ã„ã»ã©æ·±ã„ç‘æƒ³çŠ¶æ…‹ï¼ˆå†…çš„é›†ä¸­ï¼‰ã‚’ç¤ºå”†
> - **Î²/Î± (Beta/Alpha)**: è¦šé†’åº¦ã€‚å€¤ãŒä½ã„ã»ã©ãƒªãƒ©ãƒƒã‚¯ã‚¹çŠ¶æ…‹ã€é«˜ã„ã»ã©è¦šé†’ãƒ»ç·Šå¼µçŠ¶æ…‹
> - **Î²/Î¸ (Beta/Theta)**: æ³¨æ„ãƒ»é›†ä¸­åº¦ã€‚å€¤ãŒé«˜ã„ã»ã©å¤–çš„ã‚¿ã‚¹ã‚¯ã¸ã®é›†ä¸­ã‚’ç¤ºå”†

"""

    # ========================================
    # è¡€æµå‹•æ…‹åˆ†æ (fNIRS)
    # ========================================
    if "fnirs_stats" in results or "fnirs_img" in results:
        report += "## ğŸ©¸ è¡€æµå‹•æ…‹åˆ†æ (fNIRS)\n\n"

        if "fnirs_img" in results:
            report += "### HbO/HbRæ™‚ç³»åˆ—\n\n"
            report += f"![fNIRSæ™‚ç³»åˆ—](img/{results['fnirs_img']})\n\n"

        if "fnirs_stats" in results:
            report += "### çµ±è¨ˆã‚µãƒãƒªãƒ¼\n\n"
            report += results["fnirs_stats"].to_markdown(floatfmt=".2f")
            report += "\n\n"

    # ========================================
    # å‹•ä½œæ¤œå‡ºã¨å¿ƒæ‹æ•°
    # ========================================
    if "motion_stats" in results or "motion_img" in results:
        report += "## ğŸƒ å‹•ä½œæ¤œå‡ºã¨å¿ƒæ‹æ•°\n\n"

        if "motion_stats" in results:
            report += "### çµ±è¨ˆã‚µãƒãƒªãƒ¼\n\n"
            report += results["motion_stats"].to_markdown(index=False)
            report += "\n\n"
            report += "> **æ³¨**: åŠ é€Ÿåº¦ã‚»ãƒ³ã‚µãƒ¼ï¼ˆç›´ç·šç§»å‹•ï¼‰ã¨ã‚¸ãƒ£ã‚¤ãƒ­ã‚¹ã‚³ãƒ¼ãƒ—ï¼ˆé ­éƒ¨å›è»¢ï¼‰ã§å‹•ä½œã‚’æ¤œå‡ºã€‚å‹•ä½œæ¤œå‡ºã•ã‚ŒãŸåŒºé–“ã¯EEGã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\n"

        if "motion_img" in results:
            report += "### å‹•ä½œæ¤œå‡º & å¿ƒæ‹æ•°ã®æ™‚ç³»åˆ—\n\n"
            report += f"![å‹•ä½œæ¤œå‡ºãƒ»å¿ƒæ‹æ•°æ™‚ç³»åˆ—](img/{results['motion_img']})\n\n"

    # ========================================
    # æ™‚é–“çµŒéåˆ†æ
    # ========================================
    if any(key in results for key in segment_keys):
        report += "## â±ï¸ æ™‚é–“çµŒéåˆ†æ\n\n"

        if 'segment_plot' in results:
            report += "### ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹\n\n"
            report += f"![æ™‚é–“ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ¯”è¼ƒ](img/{results['segment_plot']})\n\n"

        if 'segment_table' in results:
            report += "### è©³ç´°ãƒ‡ãƒ¼ã‚¿\n\n"
            report += results['segment_table'].to_markdown(index=False, floatfmt='.3f')
            report += "\n\n"
            report += "> **æ³¨**: min = çµŒéæ™‚é–“ï¼ˆ3åˆ†é–“éš”ï¼‰\n\n"

    # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)

    print(f'âœ“ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}')


def run_full_analysis(data_path, output_dir, save_to='none', warmup_minutes=1.0):
    """
    å®Œå…¨ãªåˆ†æã‚’å®Ÿè¡Œ

    Parameters
    ----------
    data_path : Path
        å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    output_dir : Path
        å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    save_to : str, default='none'
        ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ã®ä¿å­˜å…ˆ
        - 'none': ä¿å­˜ã—ãªã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        - 'csv': ãƒ­ãƒ¼ã‚«ãƒ«CSVã«ä¿å­˜ï¼ˆé–‹ç™ºç”¨ï¼‰
        - 'sheets': Google Sheetsã«ä¿å­˜ï¼ˆæœ¬ç•ªç”¨ï¼‰
    warmup_minutes : float, default=1.0
        ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—é™¤å¤–æ™‚é–“ï¼ˆåˆ†ï¼‰ã€‚çŸ­ã„è¨˜éŒ²ã®å ´åˆã¯0ã‚’æŒ‡å®šã€‚
    """
    print('='*60)
    print('Museè„³æ³¢ãƒ‡ãƒ¼ã‚¿åŸºæœ¬åˆ†æ')
    print('='*60)
    print()

    # ç”»åƒå‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    img_dir = output_dir / 'img'
    img_dir.mkdir(exist_ok=True)

    # åˆ†æçµæœã‚’æ ¼ç´
    results = {}

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    print(f'Loading: {data_path}')
    df = load_mind_monitor_csv(data_path, filter_headband=False, warmup_seconds=warmup_minutes * 60)

    # ãƒ‡ãƒ¼ã‚¿æƒ…å ±ã‚’è¨˜éŒ²
    results['data_info'] = {
        'shape': df.shape,
        'start_time': df['TimeStamp'].min(),
        'end_time': df['TimeStamp'].max(),
        'duration_sec': (df['TimeStamp'].max() - df['TimeStamp'].min()).total_seconds()
    }

    print(f'ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {df.shape[0]} è¡Œ Ã— {df.shape[1]} åˆ—')
    print(
        f'è¨˜éŒ²æ™‚é–“: '
        f'{format_timestamp_for_report(results["data_info"]["start_time"])} '
        f'~ {format_timestamp_for_report(results["data_info"]["end_time"])}'
    )
    duration_min = seconds_to_minutes(results["data_info"]["duration_sec"])
    if duration_min is not None:
        print(f'è¨ˆæ¸¬æ™‚é–“: {duration_min:.1f} åˆ†\n')
    else:
        print('è¨ˆæ¸¬æ™‚é–“: N/A\n')

    # HSIæ¥ç¶šå“è³ªçµ±è¨ˆ
    print('è¨ˆç®—ä¸­: æ¥ç¶šå“è³ª (HSI)...')
    hsi_stats = calculate_hsi_statistics(df)
    results['hsi_stats'] = hsi_stats

    # ãƒãƒ³ãƒ‰çµ±è¨ˆ
    print('è¨ˆç®—ä¸­: ãƒãƒ³ãƒ‰çµ±è¨ˆé‡...')
    band_stats = calculate_band_statistics(df)
    results['band_statistics'] = band_stats['statistics']

    # fNIRSè§£æ
    fnirs_results = None
    try:
        optics_data = get_optics_data(df)
        if optics_data and len(optics_data['time']) > 0:
            print('è¨ˆç®—ä¸­: fNIRSçµ±è¨ˆ...')
            fnirs_results = analyze_fnirs(optics_data)
            results['fnirs_stats'] = generate_fnirs_stats_table(fnirs_results['stats'])

            print('ãƒ—ãƒ­ãƒƒãƒˆä¸­: fNIRSæ™‚ç³»åˆ—...')
            fig_fnirs, _ = plot_fnirs_muse_style(fnirs_results)
            fnirs_img_name = 'fnirs_muse_style.png'
            fig_fnirs.savefig(img_dir / fnirs_img_name, dpi=150, bbox_inches='tight')
            plt.close(fig_fnirs)
            results['fnirs_img'] = fnirs_img_name
    except KeyError as exc:
        print(f'è­¦å‘Š: fNIRSãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ã§ãã¾ã›ã‚“ã§ã—ãŸ ({exc})')

    # å‹•ä½œæ¤œå‡ºï¼ˆåŠ é€Ÿåº¦ãƒ»ã‚¸ãƒ£ã‚¤ãƒ­ï¼‰ã¨å¿ƒæ‹æ•°
    hr_data = None
    motion_result = None
    try:
        # å¿ƒæ‹æ•°ãƒ‡ãƒ¼ã‚¿å–å¾—
        hr_data = get_heart_rate_data(df)

        # å‹•ä½œæ¤œå‡ºï¼ˆ10ç§’é–“éš”ï¼‰
        print('è¨ˆç®—ä¸­: å‹•ä½œæ¤œå‡ºï¼ˆåŠ é€Ÿåº¦ãƒ»ã‚¸ãƒ£ã‚¤ãƒ­ï¼‰...')
        motion_result = analyze_motion(df, interval='10s')

        # çµ±è¨ˆæƒ…å ±ã‚’DataFrameåŒ–
        results['motion_stats'] = create_motion_stats_table(motion_result, hr_data=hr_data)

        # æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆï¼ˆå‹•ä½œæ¤œå‡º + å¿ƒæ‹æ•°ï¼‰
        print('ãƒ—ãƒ­ãƒƒãƒˆä¸­: å‹•ä½œæ¤œå‡º & å¿ƒæ‹æ•°æ™‚ç³»åˆ—...')
        motion_img_name = 'motion_heart_rate.png'
        fig_motion, _ = plot_motion_heart_rate(motion_result, hr_data=hr_data, df=df)
        fig_motion.savefig(img_dir / motion_img_name, dpi=150, bbox_inches='tight')
        plt.close(fig_motion)
        results['motion_img'] = motion_img_name
        results['motion_ratio'] = motion_result['motion_ratio']

    except Exception as exc:
        print(f'è­¦å‘Š: å‹•ä½œæ¤œå‡ºã‚’å‡¦ç†ã§ãã¾ã›ã‚“ã§ã—ãŸ ({exc})')

    # ãƒãƒ³ãƒ‰ãƒ‘ãƒ¯ãƒ¼æ™‚ç³»åˆ—ï¼ˆMuseã‚¢ãƒ—ãƒªé¢¨ï¼‰
    print('ãƒ—ãƒ­ãƒƒãƒˆä¸­: ãƒãƒ³ãƒ‰ãƒ‘ãƒ¯ãƒ¼æ™‚ç³»åˆ—...')
    df_quality, quality_mask = filter_eeg_quality(df)
    df_for_band = df_quality if not df_quality.empty else df
    plot_band_power_time_series(
        df_for_band,
        img_path=img_dir / 'band_power_time_series.png',
        rolling_window=200,
        resample_interval='10S',
        smooth_window=5,
        clip_percentile=98.0
    )
    results['band_power_img'] = 'band_power_time_series.png'
    results['band_power_quality_ratio'] = float(quality_mask.mean())

    # MNE RAWæº–å‚™
    print('æº–å‚™ä¸­: MNE RAWãƒ‡ãƒ¼ã‚¿...')
    mne_dict = prepare_mne_raw(df)
    raw = None
    raw_unfiltered = None  # FmÎ¸/FAAç”¨ã®ãƒ•ã‚£ãƒ«ã‚¿ãªã—raw

    if mne_dict:
        raw = mne_dict['raw']
        print(f'æ¤œå‡ºã•ã‚ŒãŸãƒãƒ£ãƒãƒ«: {mne_dict["channels"]}')
        print(f'æ¨å®šã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: {mne_dict["sfreq"]:.2f} Hz')

        # FmÎ¸/FAAè¨ˆç®—ç”¨ã«ã€ãƒãƒ³ãƒ‰ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨ã—ãªã„rawãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        # (ã“ã‚Œã‚‰ã®é–¢æ•°ã¯å†…éƒ¨ã§ç‹¬è‡ªã®ãƒãƒ³ãƒ‰ãƒ‘ã‚¹ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨ã™ã‚‹ãŸã‚)
        mne_dict_unfiltered = prepare_mne_raw(df, apply_bandpass=False, apply_notch=False)
        if mne_dict_unfiltered:
            raw_unfiltered = mne_dict_unfiltered['raw']

        # Rawãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
        print('ãƒ—ãƒ­ãƒƒãƒˆä¸­: ç”Ÿãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼...')
        raw_preview_img = 'raw_preview.png'
        raw_duration = raw.times[-1] if raw.n_times else 0.0
        preview_duration = raw_duration if raw_duration and raw_duration < 180 else 180.0
        plot_raw_preview(
            raw,
            img_path=img_dir / raw_preview_img,
            duration_sec=preview_duration,
            start_sec=0.0,
            n_channels=min(4, len(mne_dict['channels'])),
        )
        results['raw_preview_img'] = raw_preview_img

        # PSDè¨ˆç®—
        print('è¨ˆç®—ä¸­: ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«å¯†åº¦...')
        psd_dict = calculate_psd(raw)

        # PSDãƒ—ãƒ­ãƒƒãƒˆ
        print('ãƒ—ãƒ­ãƒƒãƒˆä¸­: ãƒ‘ãƒ¯ãƒ¼ã‚¹ãƒšã‚¯ãƒˆãƒ«å¯†åº¦...')
        plot_psd(psd_dict, img_path=img_dir / 'psd.png')
        results['psd_img'] = 'psd.png'

        # ãƒ”ãƒ¼ã‚¯å‘¨æ³¢æ•°
        results['psd_peaks'] = get_psd_peak_frequencies(psd_dict)

        # ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ï¼ˆå…¨ãƒãƒ£ãƒãƒ«ï¼‰
        # 256Hzã¯éå‰°ãªãŸã‚ã€64Hzã«ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆé«˜é€ŸåŒ–ï¼‰
        # ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã¯30Hzç¨‹åº¦ã¾ã§ã‚«ãƒãƒ¼ã§ãã‚Œã°ååˆ†
        print('è¨ˆç®—ä¸­: ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ï¼ˆå…¨ãƒãƒ£ãƒãƒ«ï¼‰...')
        raw_for_tfr = raw.copy().resample(64, verbose=False)
        tfr_results = calculate_spectrogram_all_channels(raw_for_tfr)
        tfr_primary = None
        tfr_primary_channel = None

        if tfr_results:
            print('ãƒ—ãƒ­ãƒƒãƒˆä¸­: ã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ï¼ˆå…¨ãƒãƒ£ãƒãƒ«ï¼‰...')
            plot_spectrogram_grid(tfr_results, img_path=img_dir / 'spectrogram.png')
            results['spectrogram_img'] = 'spectrogram.png'

            # æ™‚ç³»åˆ—è§£æã§å„ªå…ˆçš„ã«ä½¿ã†ãƒãƒ£ãƒãƒ«ï¼ˆTP9å„ªå…ˆã€ãªã‘ã‚Œã°æœ€åˆã®ãƒãƒ£ãƒãƒ«ï¼‰
            preferred_channels = ('RAW_TP9', 'RAW_AF7', 'RAW_AF8', 'RAW_TP10')
            for channel in preferred_channels:
                if channel in tfr_results:
                    tfr_primary = tfr_results[channel]
                    tfr_primary_channel = channel
                    break
            if tfr_primary is None:
                tfr_primary_channel, tfr_primary = next(iter(tfr_results.items()))

        # PAFåˆ†æ
        print('è¨ˆç®—ä¸­: Peak Alpha Frequency...')
        paf_dict = calculate_paf(psd_dict)

        # PAFãƒ—ãƒ­ãƒƒãƒˆ
        print('ãƒ—ãƒ­ãƒƒãƒˆä¸­: PAF...')
        plot_paf(paf_dict, img_path=img_dir / 'paf.png')
        results['paf_img'] = 'paf.png'

        # IAFã‚µãƒãƒªãƒ¼
        iaf_summary = []
        for ch_label, paf_result in paf_dict['paf_by_channel'].items():
            iaf_summary.append({
                'ãƒãƒ£ãƒãƒ«': ch_label,
                'Peak (Hz)': paf_result['PAF'],
                'CoG (Hz)': paf_result['CoG'],
                'Power (Î¼VÂ²/Hz)': paf_result['Power']
            })
        results['paf_summary'] = pd.DataFrame(iaf_summary)
        results['iaf'] = {
            'value': paf_dict['iaf'],
            'std': paf_dict['iaf_std'],
            'peak': paf_dict['iaf_peak'],
            'cog': paf_dict['iaf_cog']
        }

        # Alpha Power (Brain Recharge Score) è§£æ
        try:
            print('è¨ˆç®—ä¸­: Alpha Power (Brain Recharge Score)...')
            # Alphaåˆ—ãŒã‚ã‚‹ã‹ç¢ºèªï¼ˆMind Monitorå½¢å¼ï¼‰
            alpha_cols = ['Alpha_TP9', 'Alpha_AF7', 'Alpha_AF8', 'Alpha_TP10']
            has_alpha_data = all(
                col in df.columns and df[col].notna().any()
                for col in alpha_cols
            )
            if has_alpha_data:
                alpha_power_result = calculate_alpha_power(df)
            else:
                # RAW EEGã‹ã‚‰Alpha Powerã‚’è¨ˆç®—ï¼ˆMuse App OSCå½¢å¼ï¼‰
                print('  Alphaåˆ—ãŒç©ºã®ãŸã‚ã€RAW EEGã‹ã‚‰è¨ˆç®—...')
                alpha_power_result = calculate_alpha_power_from_raw(df)
            results['alpha_power_score'] = alpha_power_result.score
            results['alpha_power_db'] = alpha_power_result.alpha_db
            results['alpha_power_stats'] = alpha_power_result.statistics
            results['alpha_power_metadata'] = alpha_power_result.metadata
        except Exception as exc:
            print(f'è­¦å‘Š: Alpha Powerè§£æã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})')

        # FAAè§£æ
        try:
            print('è¨ˆç®—ä¸­: Frontal Alpha Asymmetry...')
            faa_result = calculate_frontal_asymmetry(df, raw=raw_unfiltered)
            print('ãƒ—ãƒ­ãƒƒãƒˆä¸­: Frontal Alpha Asymmetry...')
            plot_frontal_asymmetry(
                faa_result,
                img_path=img_dir / 'frontal_alpha_asymmetry.png'
            )
            results['faa_img'] = 'frontal_alpha_asymmetry.png'
            results['faa_stats'] = faa_result.statistics
        except Exception as exc:
            print(f'è­¦å‘Š: FAAè§£æã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})')

        # Spectral Entropyè§£æ
        try:
            print('è¨ˆç®—ä¸­: Spectral Entropy...')

            # PSDã‹ã‚‰å…¨ä½“ã®ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’è¨ˆç®—
            se_result = calculate_spectral_entropy(psd_dict)

            # æ™‚ç³»åˆ—ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã®è¨ˆç®—ï¼ˆã‚¹ãƒšã‚¯ãƒˆãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰ï¼‰
            if tfr_primary:
                session_start = df['TimeStamp'].iloc[0]
                se_time_result = calculate_spectral_entropy_time_series(
                    tfr_primary,
                    start_time=pd.to_datetime(session_start)
                )

                results['spectral_entropy_stats'] = se_time_result.statistics
                results['spectral_entropy_change'] = se_time_result.metadata.get('change_percent')
        except Exception as exc:
            print(f'è­¦å‘Š: Spectral Entropyè§£æã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})')

    # Frontal Midline Thetaè§£æ
    fmtheta_result = None
    try:
        print('è¨ˆç®—ä¸­: Frontal Midline Theta...')
        fmtheta_result = calculate_frontal_theta(df, raw=raw_unfiltered if raw_unfiltered else None)
        print('ãƒ—ãƒ­ãƒƒãƒˆä¸­: Frontal Midline Theta...')
        plot_frontal_theta(
            fmtheta_result,
            img_path=img_dir / 'frontal_midline_theta.png'
        )
        results['frontal_theta_img'] = 'frontal_midline_theta.png'
        results['frontal_theta_stats'] = fmtheta_result.statistics
        results['frontal_theta_increase'] = fmtheta_result.metadata.get('increase_rate_percent')
    except Exception as exc:
        print(f'è­¦å‘Š: FmÎ¸è§£æã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})')

    # Statistical DataFrameç”Ÿæˆï¼ˆçµ±ä¸€çš„ãªãƒãƒ³ãƒ‰ãƒ‘ãƒ¯ãƒ¼ãƒ»æ¯”ç‡è¨ˆç®—ï¼‰
    statistical_df = None
    if raw is not None:
        try:
            print('è¨ˆç®—ä¸­: Statistical DataFrameï¼ˆçµ±ä¸€çš„ãªãƒãƒ³ãƒ‰ãƒ‘ãƒ¯ãƒ¼ãƒ»æ¯”ç‡è¨ˆç®—ï¼‰...')
            session_start = df['TimeStamp'].iloc[0]
            statistical_df = create_statistical_dataframe(
                raw,
                segment_minutes=3,
                warmup_minutes=warmup_minutes,
                session_start=session_start,
                fnirs_results=fnirs_results,
                hr_data=hr_data,
                df_timestamps=df['TimeStamp'],
            )
            results['statistical_df'] = statistical_df
            print(f'  ãƒãƒ³ãƒ‰ãƒ‘ãƒ¯ãƒ¼: {len(statistical_df["band_powers"])} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ')
            print(f'  ãƒãƒ³ãƒ‰æ¯”ç‡: {len(statistical_df["band_ratios"])} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ')
        except Exception as exc:
            print(f'è­¦å‘Š: Statistical DataFrameç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})')

    # æ™‚é–“ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æ
    try:
        print('è¨ˆç®—ä¸­: æ™‚é–“ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æ...')

        if statistical_df is None:
            print('è­¦å‘Š: Statistical DFãŒç”Ÿæˆã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚')
            raise ValueError('Statistical DFãŒå¿…è¦ã§ã™')

        # IAFã¯Statistical DFã«å«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ã€æº–å‚™ä¸è¦
        segment_result = calculate_segment_analysis(
            df_quality,
            fmtheta_result.time_series,
            statistical_df,
            segment_minutes=3,
            warmup_minutes=warmup_minutes,
            exclude_first_segment=True,  # relaxing phase
            exclude_last_segment=True,   # post meditation stage
        )
        print('ãƒ—ãƒ­ãƒƒãƒˆä¸­: æ™‚é–“ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ¯”è¼ƒ...')
        segment_plot_name = 'time_segment_metrics.png'
        plot_segment_comparison(
            segment_result,
            img_path=img_dir / segment_plot_name,
        )
        results['segment_table'] = segment_result.table
        results['segment_plot'] = segment_plot_name
        results['segment_peak_range'] = segment_result.metadata.get('peak_time_range')
        results['segment_peak_score'] = segment_result.metadata.get('peak_score')

        # bestå€¤ã‚’è¨ˆç®—
        best_metrics = calculate_best_metrics(segment_result)
        results['best_metrics'] = best_metrics

        # meanå€¤ã‚’è¨ˆç®—ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®å¹³å‡ï¼‰
        segments = segment_result.segments
        mean_metrics = {
            'fm_theta_mean': segments['fmtheta_mean'].mean() if 'fmtheta_mean' in segments else None,
            'iaf_mean': segments['iaf_mean'].mean() if 'iaf_mean' in segments else None,
            'alpha_mean': segments['alpha_mean'].mean() if 'alpha_mean' in segments else None,
            'beta_mean': segments['beta_mean'].mean() if 'beta_mean' in segments else None,
            'theta_alpha_mean': segments['theta_alpha_ratio'].mean() if 'theta_alpha_ratio' in segments else None,
        }
        results['mean_metrics'] = mean_metrics

    except Exception as exc:
        print(f'è­¦å‘Š: æ™‚é–“ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})')

    # ãƒãƒ³ãƒ‰æ¯”ç‡ï¼ˆStatistical DFã‹ã‚‰å–å¾—ï¼‰
    if statistical_df is not None:
        print('ãƒãƒ³ãƒ‰æ¯”ç‡çµ±è¨ˆã‚’Statistical DFã‹ã‚‰å–å¾—...')
        results['band_ratios_stats'] = statistical_df['statistics']

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒãƒ³ãƒ‰æ¯”ç‡ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        try:
            print('ãƒ—ãƒ­ãƒƒãƒˆä¸­: ãƒãƒ³ãƒ‰æ¯”ç‡...')
            if 'segment_table' in results:
                plot_band_ratios(
                    results['segment_table'],
                    img_path=img_dir / 'band_ratios.png',
                )
                results['band_ratios_img'] = 'band_ratios.png'
            else:
                print('è­¦å‘Š: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ãŒãªã„ãŸã‚ã€ãƒãƒ³ãƒ‰æ¯”ç‡ãƒ—ãƒ­ãƒƒãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚')
        except Exception as exc:
            print(f'è­¦å‘Š: ãƒãƒ³ãƒ‰æ¯”ç‡ãƒ—ãƒ­ãƒƒãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})')
            import traceback
            traceback.print_exc()
    else:
        print('è­¦å‘Š: Statistical DFãŒç”Ÿæˆã•ã‚Œã¦ã„ãªã„ãŸã‚ã€ãƒãƒ³ãƒ‰æ¯”ç‡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚')

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
    try:
        print('è¨ˆç®—ä¸­: ã‚»ãƒƒã‚·ãƒ§ãƒ³ç·åˆã‚¹ã‚³ã‚¢...')

        # å„æŒ‡æ¨™ã‹ã‚‰å¿…è¦ãªå€¤ã‚’æŠ½å‡º
        fmtheta_val = None
        if fmtheta_result and 'frontal_theta_stats' in results:
            # å¹³å‡å€¤ã‚’å–å¾—
            stats_df = results['frontal_theta_stats']
            fmtheta_row = stats_df[stats_df['Metric'] == 'Mean']
            if not fmtheta_row.empty:
                fmtheta_val = fmtheta_row['Value'].iloc[0]

        se_val = None
        if 'spectral_entropy_stats' in results:
            se_stats_df = results['spectral_entropy_stats']
            se_row = se_stats_df[se_stats_df['Metric'] == 'Mean']
            if not se_row.empty:
                se_val = se_row['Value'].iloc[0]

        theta_alpha_val = None
        beta_alpha_val = None
        beta_theta_val = None

        # ãƒãƒ³ãƒ‰æ¯”ç‡: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æã‹ã‚‰å–å¾—ï¼ˆStatistical DFãƒ™ãƒ¼ã‚¹ã€æœ€ã‚‚ä¿¡é ¼æ€§ãŒé«˜ã„ï¼‰
        if 'segment_table' in results:
            segment_df = results['segment_table']

            # Î¸/Î±æ¯”ï¼ˆå®Ÿæ•°æ¯”ç‡ï¼‰: ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ç”¨
            if 'Î¸/Î±' in segment_df.columns:
                theta_alpha_values = segment_df['Î¸/Î±'].dropna()
                if len(theta_alpha_values) > 0:
                    theta_alpha_val = theta_alpha_values.mean()

            # Î²/Î±æ¯”ï¼ˆå®Ÿæ•°æ¯”ç‡ï¼‰
            if 'Î²/Î±' in segment_df.columns:
                beta_alpha_values = segment_df['Î²/Î±'].dropna()
                if len(beta_alpha_values) > 0:
                    beta_alpha_val = beta_alpha_values.mean()

            # Î²/Î¸æ¯”ï¼ˆå®Ÿæ•°æ¯”ç‡ï¼‰
            if 'Î²/Î¸' in segment_df.columns:
                beta_theta_values = segment_df['Î²/Î¸'].dropna()
                if len(beta_theta_values) > 0:
                    beta_theta_val = beta_theta_values.mean()
                    results['beta_theta_ratio'] = beta_theta_val  # ãƒ¬ãƒãƒ¼ãƒˆç”¨ã«ä¿å­˜

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: Statistical DFã‹ã‚‰ç›´æ¥å–å¾—
        if theta_alpha_val is None and statistical_df is not None:
            stats_df = statistical_df['statistics']
            theta_alpha_row = stats_df[stats_df['Metric'] == 'theta_alpha_db_Mean']
            if not theta_alpha_row.empty:
                theta_alpha_val = theta_alpha_row['Value'].iloc[0]

        if beta_alpha_val is None and statistical_df is not None:
            stats_df = statistical_df['statistics']
            beta_alpha_row = stats_df[stats_df['Metric'] == 'beta_alpha_Mean']
            if not beta_alpha_row.empty:
                beta_alpha_val = beta_alpha_row['Value'].iloc[0]

        faa_val = None
        if 'faa_stats' in results:
            faa_stats_df = results['faa_stats']
            faa_row = faa_stats_df[faa_stats_df['Metric'] == 'Mean FAA']
            if not faa_row.empty:
                faa_val = faa_row['Value'].iloc[0]

        iaf_cv_val = None

        # Statistical DFã‹ã‚‰ç›´æ¥IAFå¤‰å‹•ä¿‚æ•°ã‚’å–å¾—ï¼ˆæœ€ã‚‚ä¿¡é ¼æ€§ãŒé«˜ã„ï¼‰
        if statistical_df is not None and 'statistics' in statistical_df:
            stats_df = statistical_df['statistics']
            iaf_cv_row = stats_df[stats_df['Metric'] == 'iaf_CV']
            if not iaf_cv_row.empty:
                iaf_cv_val = iaf_cv_row['Value'].iloc[0]

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†æã‹ã‚‰è¨ˆç®—
        if iaf_cv_val is None and 'segment_table' in results:
            segment_df = results['segment_table']
            if 'IAF (Hz)' in segment_df.columns:
                iaf_values = segment_df['IAF (Hz)'].dropna()
                if len(iaf_values) > 1:
                    iaf_mean = iaf_values.mean()
                    iaf_std = iaf_values.std()
                    if iaf_mean > 0:
                        iaf_cv_val = iaf_std / iaf_mean

        hsi_quality_val = None
        if 'hsi_stats' in results:
            hsi_stats = results['hsi_stats']
            if 'avg_quality' in hsi_stats:
                hsi_quality_val = hsi_stats['avg_quality']

        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        session_score = calculate_meditation_score(
            fmtheta=fmtheta_val,
            spectral_entropy=se_val,
            theta_alpha_ratio=theta_alpha_val,
            faa=faa_val,
            beta_alpha_ratio=beta_alpha_val,
            iaf_cv=iaf_cv_val,
            hsi_quality=hsi_quality_val,
        )

        results['session_score'] = session_score['total_score']
        results['session_level'] = session_score['level']
        results['session_score_breakdown'] = session_score['scores']

    except Exception as exc:
        print(f'è­¦å‘Š: ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})')

    # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    generate_markdown_report(data_path, output_dir, results)

    # ã‚µãƒãƒªãƒ¼CSVç”Ÿæˆ
    print('ç”Ÿæˆä¸­: ã‚µãƒãƒªãƒ¼CSV...')
    summary_result = generate_session_summary(data_path, results)
    summary_csv_path = output_dir / 'summary.csv'
    summary_result.summary.to_csv(summary_csv_path, index=False, encoding='utf-8')
    print(f'âœ“ ã‚µãƒãƒªãƒ¼CSVç”Ÿæˆå®Œäº†: {summary_csv_path}')

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ä¿å­˜ï¼ˆé–‹ç™ºç”¨CSV ã¾ãŸã¯ æœ¬ç•ªç”¨Google Sheetsï¼‰
    if save_to == 'csv':
        print('æ›´æ–°ä¸­: ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ï¼ˆCSVï¼‰...')
        try:
            csv_path = write_to_csv(results=results)
            print(f'âœ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°CSVæ›´æ–°: {csv_path}')
        except Exception as exc:
            print(f'è­¦å‘Š: ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°CSVæ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})')
    elif save_to == 'sheets':
        print('æ›´æ–°ä¸­: ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ï¼ˆGoogle Sheetsï¼‰...')
        try:
            spreadsheet_id = os.environ.get('GSHEET_SESSION_LOG_ID')
            if not spreadsheet_id:
                print('è­¦å‘Š: ç’°å¢ƒå¤‰æ•° GSHEET_SESSION_LOG_ID ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“')
            else:
                write_to_google_sheets(
                    results=results,
                    spreadsheet_id=spreadsheet_id,
                )
                print(f'âœ“ Google Sheetsæ›´æ–°: {spreadsheet_id}')
        except Exception as exc:
            print(f'è­¦å‘Š: Google Sheetsæ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ ({exc})')
    else:
        print('ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ã¸ã®ä¿å­˜ã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã—ãŸï¼ˆ--save-to ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§æŒ‡å®šï¼‰')

    print()
    print('='*60)
    print('åˆ†æå®Œäº†!')
    print('='*60)
    print(f'ãƒ¬ãƒãƒ¼ãƒˆ: {output_dir / "REPORT.md"}')
    print(f'ã‚µãƒãƒªãƒ¼: {summary_csv_path}')
    print(f'ç”»åƒ: {img_dir}/')


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(
        description='Museè„³æ³¢ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬åˆ†æã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ç‰ˆï¼‰'
    )
    parser.add_argument(
        '--data',
        type=Path,
        required=True,
        help='å…¥åŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹'
    )
    parser.add_argument(
        '--output',
        type=Path,
        default=Path(__file__).parent,
        help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰'
    )
    parser.add_argument(
        '--save-to',
        type=str,
        choices=['none', 'csv', 'sheets'],
        default='none',
        help='ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ­ã‚°ã®ä¿å­˜å…ˆ: none=ä¿å­˜ã—ãªã„ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰, csv=ãƒ­ãƒ¼ã‚«ãƒ«CSVï¼ˆé–‹ç™ºç”¨ï¼‰, sheets=Google Sheetsï¼ˆæœ¬ç•ªç”¨ï¼‰'
    )
    parser.add_argument(
        '--warmup',
        type=float,
        default=1.0,
        help='ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—é™¤å¤–æ™‚é–“ï¼ˆåˆ†ï¼‰ã€‚çŸ­ã„è¨˜éŒ²ã®å ´åˆã¯0ã‚’æŒ‡å®šï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 1.0ï¼‰'
    )

    args = parser.parse_args()

    # ãƒ‘ã‚¹ã®æ¤œè¨¼
    if not args.data.exists():
        print(f'ã‚¨ãƒ©ãƒ¼: ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.data}')
        return 1

    args.output.mkdir(parents=True, exist_ok=True)

    # åˆ†æå®Ÿè¡Œ
    run_full_analysis(args.data, args.output, save_to=args.save_to, warmup_minutes=args.warmup)

    return 0


if __name__ == '__main__':
    exit(main())
